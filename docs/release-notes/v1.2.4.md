# Brainarr 1.2.4 - 2025-09-23

## Highlights

- **Prompt planner/renderer split**: Separated planning and rendering into dedicated services backed by a fingerprinted LRU/TTL plan cache with hit/miss/evict telemetry, keeping prompts deterministic and observable at scale.
- **Token drift guardrails**: Library-aware prompt builder now invalidates cached plans when compression drifts beyond 30 % and preserves deterministic ordering after trimming, preventing runaway prompts.
- **Provider-aware templates**: Anthropic and Gemini now receive strict JSON instructions, aligning real responses with the structured output Brainarr expects.
- **Runtime stability**: Fixed the DryIoc orchestrator recursion and stabilized the smoke-test workflow by waiting for Lidarr assemblies before the sanity build executes.

## Compatibility

- Lidarr **2.14.1.4716+** on the `nightly` (plugins) branch remains required.
- No database migrations are needed from 1.2.3 → 1.2.4.

## Provider Verification Snapshot

Verified in 1.2.4 smoke tests:

- ✅ **LM Studio** – Qwen 3 via LM Studio local server
- ✅ **Google Gemini** – `Gemini_25_Flash` using AI Studio API keys
- ✅ **Perplexity** – `Sonar_Pro`

Pending re-verification post-1.2.4:

- Ollama, OpenAI, Anthropic, OpenRouter, DeepSeek, Groq

## Upgrade Notes

1. Install or update Brainarr via **Settings → Plugins → Add Plugin** in Lidarr, pointing to `https://github.com/RicherTunes/Brainarr`.
2. Restart Lidarr after deployment so the new assemblies and manifests load.
3. Review provider settings; Anthropic and Gemini users should confirm structured JSON output is enabled.
4. Monitor the new prompt-plan cache metrics (`prompt.plan_cache_*`) in your telemetry backend to ensure cache hit ratios stay healthy.

## Links

- [Changelog](../CHANGELOG.md#124---2025-09-23)
- [Provider Support Matrix](../PROVIDER_SUPPORT_MATRIX.md)
- [Provider Guide](../PROVIDER_GUIDE.md)
